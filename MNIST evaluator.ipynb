{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import idx2numpy as idx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i = 0\n",
    "\n",
    "file = \"mnist dataset/train-labels.idx1-ubyte\"\n",
    "labels = idx.convert_from_file(file)\n",
    "\n",
    "file = \"mnist dataset/train-images.idx3-ubyte\"\n",
    "images = idx.convert_from_file(file)\n",
    "\n",
    "def linearizeOne(image):\n",
    "    arr = [0]*len(image)*len(image)\n",
    "    i = 0\n",
    "    for j in range(len(image)):\n",
    "        for k in range(len(image[0])):\n",
    "            arr[i] = [image[j][k]]\n",
    "            i += 1\n",
    "    return arr\n",
    "\n",
    "def linearizeAll(images):\n",
    "    arr = [0]*len(images)\n",
    "    for i in range(len(images)):        \n",
    "        arr[i] = linearizeOne(images[i])\n",
    "    return np.array(arr)/256\n",
    "\n",
    "def fix_labels(labels):\n",
    "    arr = [0]*len(labels)\n",
    "    for i in range(len(labels)):\n",
    "        arr[i] = [[0] for i in range(10)]\n",
    "        arr[i][labels[i]] = [1]\n",
    "    return np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = linearizeAll(images)\n",
    "training_outputs = fix_labels(labels)\n",
    "\n",
    "# clearing memory\n",
    "# labels = []\n",
    "# images = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "\n",
    "    def __init__(self, sizes): # sizes tell how many neurons are there in each layer from input to output\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(sizes)\n",
    "        self.biases = [np.random.randn(i,1) for i in self.sizes[1:]] # output or intermediate number of biases. a column matrix\n",
    "        self.weights = [np.random.randn(self.sizes[i+1], self.sizes[i]) for i in range(self.num_layers-1)] # prev_layer X curr_layer dimension\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1 + np.exp(-z))\n",
    "    \n",
    "    def sigmoid_derivative(self, z):\n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "    \n",
    "    def feedforward(self, a):\n",
    "        for w,b in zip(self.weights, self.biases):\n",
    "            a = self.sigmoid(np.dot(w,a) + b)\n",
    "        return a\n",
    "    \n",
    "    def cost_derivative(self, a, y):\n",
    "        return a-y\n",
    "\n",
    "    def backprop(self, x, y): # return delta_b and delta_a arrays\n",
    "        # x is input and y is output\n",
    "\n",
    "        delta_w = [np.zeros(w.shape) for w in self.weights]    \n",
    "        delta_b = [np.zeros(b.shape) for b in self.biases]\n",
    "    \n",
    "        # forward pass\n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        zs = []\n",
    "        for w,b in zip(self.weights, self.biases):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = self.sigmoid(z)\n",
    "            activations.append(activation)\n",
    "\n",
    "        # backward pass\n",
    "\n",
    "        delta = self.cost_derivative(activations[-1], y)*self.sigmoid_derivative(zs[-1])\n",
    "        delta_b[-1] = delta\n",
    "        delta_w[-1] = np.dot(delta, activations[-2].T)\n",
    "\n",
    "        for i in range(2, self.num_layers):\n",
    "            z = zs[-i]\n",
    "            delta = np.dot(self.weights[-i+1].T, delta) * self.sigmoid_derivative(z)\n",
    "            delta_b[-i] = delta\n",
    "            delta_w[-i] = np.dot(delta, activations[-i-1].T)\n",
    "\n",
    "        return (delta_w, delta_b)\n",
    "    \n",
    "    def epoch_train(self, training_data, labels, epochs, batch_size, learning_rate, test_data, test_labels):\n",
    "        for i in range(epochs):\n",
    "            t = list(zip(training_data, labels))\n",
    "            np.random.shuffle(t)\n",
    "            training_data = [j[0] for j in t]\n",
    "            labels = [j[1] for j in t]\n",
    "            batches = [(training_data[k:k+batch_size], labels[k:k+batch_size]) for k in range(0, len(training_data), batch_size)]\n",
    "            for batch, label in batches:\n",
    "                self.train(batch, label, learning_rate)\n",
    "            hits = 0\n",
    "            for j in range(len(test_data)):\n",
    "                if (self.evaluate(test_labels[j]) == self.evaluate(self.feedforward(test_data[j]))):\n",
    "                    hits += 1\n",
    "            print(f\"epoch {i+1}: {hits}/{len(test_data)}\")\n",
    "            \n",
    "\n",
    "    def train(self, training_data, labels, learning_rate):\n",
    "\n",
    "        delta_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        delta_b = [np.zeros(b.shape) for b in self.biases]\n",
    "\n",
    "        for im, lb in zip(training_data, labels):\n",
    "            DDW, DDB = self.backprop(im, lb)\n",
    "            delta_w = [dw + ddw for dw, ddw in zip(delta_w, DDW)]\n",
    "            delta_b = [db + ddb for db, ddb in zip(delta_b, DDB)]\n",
    "        \n",
    "        self.weights = [w - (learning_rate/len(training_data)*dw) for w, dw in zip(self.weights, delta_w)]\n",
    "        self.biases = [b - (learning_rate/len(training_data))*db for b, db in zip(self.biases, delta_b)]\n",
    "\n",
    "\n",
    "    def predict(self, inp):\n",
    "        a = self.feedforward(inp)\n",
    "        m = 0\n",
    "        j = 0\n",
    "        for i in range(len(a)):\n",
    "            if a[i] > m:\n",
    "                m = a[i]\n",
    "                j = i\n",
    "        return j\n",
    "    \n",
    "    def evaluate(self, a):\n",
    "        m = 0\n",
    "        j = 0\n",
    "        for i in range(len(a)):\n",
    "            if a[i] > m:\n",
    "                m = a[i]\n",
    "                j = i\n",
    "        return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "file = \"mnist dataset/t10k-images.idx3-ubyte\"\n",
    "images = idx.convert_from_file(file)\n",
    "\n",
    "file = \"mnist dataset/t10k-labels.idx1-ubyte\"\n",
    "labels = idx.convert_from_file(file)\n",
    "\n",
    "testing_input = linearizeAll(images)\n",
    "testing_ouput = fix_labels(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: 9165/10000\n",
      "epoch 2: 9331/10000\n",
      "epoch 3: 9369/10000\n",
      "epoch 4: 9408/10000\n",
      "epoch 5: 9408/10000\n",
      "epoch 6: 9438/10000\n",
      "epoch 7: 9480/10000\n",
      "epoch 8: 9448/10000\n",
      "epoch 9: 9473/10000\n",
      "epoch 10: 9468/10000\n",
      "epoch 11: 9470/10000\n",
      "epoch 12: 9488/10000\n",
      "epoch 13: 9500/10000\n",
      "epoch 14: 9485/10000\n",
      "epoch 15: 9507/10000\n",
      "epoch 16: 9518/10000\n",
      "epoch 17: 9478/10000\n",
      "epoch 18: 9488/10000\n",
      "epoch 19: 9513/10000\n",
      "epoch 20: 9523/10000\n",
      "epoch 21: 9532/10000\n",
      "epoch 22: 9518/10000\n",
      "epoch 23: 9506/10000\n",
      "epoch 24: 9537/10000\n",
      "epoch 25: 9533/10000\n",
      "epoch 26: 9527/10000\n",
      "epoch 27: 9525/10000\n",
      "epoch 28: 9526/10000\n",
      "epoch 29: 9542/10000\n",
      "epoch 30: 9530/10000\n"
     ]
    }
   ],
   "source": [
    "N = NeuralNet([784, 30, 10])\n",
    "\n",
    "N.epoch_train(training_data=training_inputs, labels=training_outputs, epochs = 30, batch_size=10, learning_rate=3.0, test_data=testing_input, test_labels=testing_ouput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "\n",
    "a = N.predict(testing_input[i])\n",
    "b = labels[i]\n",
    "\n",
    "print(a, b)\n",
    "\n",
    "plt.imshow(images[i], cmap = plt.cm.binary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
