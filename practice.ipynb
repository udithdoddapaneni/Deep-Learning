{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import idx2numpy as idx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i = 0\n",
    "\n",
    "file = \"mnist dataset/train-labels.idx1-ubyte\"\n",
    "labels = idx.convert_from_file(file)\n",
    "\n",
    "file = \"mnist dataset/train-images.idx3-ubyte\"\n",
    "images = idx.convert_from_file(file)\n",
    "# plt.imshow(images[i], cmap = plt.cm.binary)\n",
    "\n",
    "def linearizeOne(image):\n",
    "    arr = [0]*len(image)*len(image)\n",
    "    i = 0\n",
    "    for j in range(len(image)):\n",
    "        for k in range(len(image[0])):\n",
    "            arr[i] = [image[j][k]]\n",
    "            i += 1\n",
    "    return arr\n",
    "\n",
    "def linearizeAll(images):\n",
    "    arr = [0]*len(images)\n",
    "    for i in range(len(images)):        \n",
    "        arr[i] = linearizeOne(images[i])\n",
    "    return np.array(arr)/1000\n",
    "\n",
    "def fix_labels(labels):\n",
    "    arr = [0]*len(labels)\n",
    "    for i in range(len(labels)):\n",
    "        arr[i] = [labels[i]]\n",
    "    return np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = linearizeAll(images)\n",
    "training_outputs = fix_labels(labels)\n",
    "# clearing memory\n",
    "# labels = []\n",
    "# images = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "\n",
    "    def __init__(self, sizes): # sizes tell how many neurons are there in each layer from input to output\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(sizes)\n",
    "        self.biases = [np.random.randn(i,1) for i in self.sizes[1:]] # output or intermediate number of biases. a column matrix\n",
    "        self.weights = [np.random.randn(self.sizes[i+1], self.sizes[i]) for i in range(self.num_layers-1)] # prev_layer X curr_layer dimension\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1 + np.exp(-z))\n",
    "    \n",
    "    def sigmoid_derivative(self, z):\n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "    \n",
    "    def feedforward(self, a):\n",
    "        for w,b in zip(self.weights, self.biases):\n",
    "            a = self.sigmoid(np.dot(w,a) + b)\n",
    "        return a\n",
    "    \n",
    "    def cost_derivative(self, a, y):\n",
    "        return a-y\n",
    "\n",
    "    def backprop(self, x, y): # return delta_b and delta_a arrays\n",
    "        # x is input and y is output\n",
    "\n",
    "        delta_w = [np.zeros(w.shape) for w in self.weights]    \n",
    "        delta_b = [np.zeros(b.shape) for b in self.biases]\n",
    "    \n",
    "        # forward pass\n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        zs = []\n",
    "        for w,b in zip(self.weights, self.biases):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = self.sigmoid(z)\n",
    "            activations.append(activation)\n",
    "\n",
    "        # backward pass\n",
    "\n",
    "        delta = self.cost_derivative(activations[-1], y)*self.sigmoid_derivative(zs[-1])\n",
    "        delta_b[-1] = delta\n",
    "        delta_w[-1] = np.dot(delta, activations[-2].T)\n",
    "\n",
    "        for i in range(2, self.num_layers):\n",
    "            z = zs[-i]\n",
    "            delta = np.dot(self.weights[-i+1].T, delta) * self.sigmoid_derivative(z)\n",
    "            delta_b[-i] = delta\n",
    "            delta_w[-i] = np.dot(delta, activations[-i-1].T)\n",
    "\n",
    "        return (delta_w, delta_b)\n",
    "    \n",
    "    def epoch_train(self, training_data, labels, epochs, batch_size, learning_rate, test_data, test_labels):\n",
    "        for i in range(epochs):\n",
    "            t = list(zip(training_data, labels))\n",
    "            np.random.shuffle(t)\n",
    "            training_data = [j[0] for j in t]\n",
    "            labels = [j[1] for j in t]\n",
    "            batches = [(training_data[k:k+batch_size], labels[k:k+batch_size])  for k in range(0, len(training_data), batch_size)]\n",
    "            for batch, label in batches:\n",
    "                self.train(batch, label, learning_rate)\n",
    "            hits = 0\n",
    "            for j in range(len(test_data)):\n",
    "                if test_labels[j] == self.predict(test_data[j]):\n",
    "                    hits += 1\n",
    "            print(f\"epoch {i+1}: {hits}/{len(test_data)}\")\n",
    "            \n",
    "\n",
    "    def train(self, training_data, labels, learning_rate):\n",
    "\n",
    "\n",
    "        delta_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        delta_b = [np.zeros(b.shape) for b in self.biases]\n",
    "\n",
    "        for im, lb in zip(training_data, labels):\n",
    "            DDW, DDB = self.backprop(im, lb)\n",
    "            delta_w = [dw + ddw for dw, ddw in zip(delta_w, DDW)]\n",
    "            delta_b = [db + ddb for db, ddb in zip(delta_b, DDB)]\n",
    "        \n",
    "        self.weights = [w - (learning_rate/len(training_data)*dw) for w, dw in zip(self.weights, delta_w)]\n",
    "        self.biases = [b - (learning_rate/len(training_data))*db for b, db in zip(self.biases, delta_b)]\n",
    "\n",
    "\n",
    "    def predict(self, inp):\n",
    "        a = self.feedforward(inp)\n",
    "        m = 0\n",
    "        j = 0\n",
    "        for i in range(len(a)):\n",
    "            if a[i] > m:\n",
    "                m = a[i]\n",
    "                j = i\n",
    "        return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "# file = \"mnist dataset/t10k-images.idx3-ubyte\"\n",
    "# images = idx.convert_from_file(file)\n",
    "\n",
    "# file = \"mnist dataset/t10k-labels.idx1-ubyte\"\n",
    "# labels = idx.convert_from_file(file)\n",
    "\n",
    "# testing_input = linearizeAll(images)\n",
    "# testing_ouput = fix_labels(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: 97/1000\n",
      "epoch 2: 97/1000\n",
      "epoch 3: 97/1000\n",
      "epoch 4: 97/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m N \u001b[38;5;241m=\u001b[39m NeuralNet([\u001b[38;5;241m784\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m10\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m \u001b[43mN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[102], line 61\u001b[0m, in \u001b[0;36mNeuralNet.epoch_train\u001b[0;34m(self, training_data, labels, epochs, batch_size, learning_rate, test_data, test_labels)\u001b[0m\n\u001b[1;32m     59\u001b[0m batches \u001b[38;5;241m=\u001b[39m [(training_data[k:k\u001b[38;5;241m+\u001b[39mbatch_size], labels[k:k\u001b[38;5;241m+\u001b[39mbatch_size])  \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(training_data), batch_size)]\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, label \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m hits \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_data)):\n",
      "Cell \u001b[0;32mIn[102], line 76\u001b[0m, in \u001b[0;36mNeuralNet.train\u001b[0;34m(self, training_data, labels, learning_rate)\u001b[0m\n\u001b[1;32m     73\u001b[0m delta_b \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mzeros(b\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m im, lb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(training_data, labels):\n\u001b[0;32m---> 76\u001b[0m     DDW, DDB \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     delta_w \u001b[38;5;241m=\u001b[39m [dw \u001b[38;5;241m+\u001b[39m ddw \u001b[38;5;28;01mfor\u001b[39;00m dw, ddw \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(delta_w, DDW)]\n\u001b[1;32m     78\u001b[0m     delta_b \u001b[38;5;241m=\u001b[39m [db \u001b[38;5;241m+\u001b[39m ddb \u001b[38;5;28;01mfor\u001b[39;00m db, ddb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(delta_b, DDB)]\n",
      "Cell \u001b[0;32mIn[102], line 26\u001b[0m, in \u001b[0;36mNeuralNet.backprop\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y): \u001b[38;5;66;03m# return delta_b and delta_a arrays\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# x is input and y is output\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     delta_w \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mzeros(w\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights]    \n\u001b[1;32m     27\u001b[0m     delta_b \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mzeros(b\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases]\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# forward pass\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[102], line 26\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y): \u001b[38;5;66;03m# return delta_b and delta_a arrays\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# x is input and y is output\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     delta_w \u001b[38;5;241m=\u001b[39m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights]    \n\u001b[1;32m     27\u001b[0m     delta_b \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mzeros(b\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases]\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# forward pass\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N = NeuralNet([784, 30, 10])\n",
    "\n",
    "N.epoch_train(training_data=training_inputs, labels=training_outputs, epochs = 30, batch_size=30, learning_rate=3, test_data=training_inputs[:1000], test_labels=labels[:1000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
