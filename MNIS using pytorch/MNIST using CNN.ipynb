{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True,\n",
    ")\n",
    "\n",
    "train_data.data = train_data.data.type(torch.float32)\n",
    "train_data.targets = train_data.targets.type(torch.float32)\n",
    "\n",
    "test_data.data = test_data.data.type(torch.float32)\n",
    "test_data.targets = test_data.targets.type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: 9375/10000\n",
      "epoch 1: 9596/10000\n",
      "epoch 2: 9627/10000\n",
      "epoch 3: 9721/10000\n",
      "epoch 4: 9766/10000\n",
      "epoch 5: 9771/10000\n",
      "epoch 6: 9774/10000\n",
      "epoch 7: 9767/10000\n",
      "epoch 8: 9803/10000\n",
      "epoch 9: 9825/10000\n",
      "epoch 10: 9833/10000\n",
      "epoch 11: 9839/10000\n",
      "epoch 12: 9830/10000\n",
      "epoch 13: 9843/10000\n",
      "epoch 14: 9835/10000\n",
      "epoch 15: 9825/10000\n",
      "epoch 16: 9836/10000\n",
      "epoch 17: 9850/10000\n",
      "epoch 18: 9834/10000\n",
      "epoch 19: 9849/10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "def fix_input(x):\n",
    "    return x/255.0\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_data, batch_size=10, shuffle=False, num_workers=1)\n",
    "\n",
    "# for idx, (data, target) in enumerate(train_loader):\n",
    "#     print(data[0][0].shape)\n",
    "\n",
    "def conv(y):\n",
    "    arr = [0]*10\n",
    "    arr[int(y.item())] = 1.0\n",
    "    return torch.tensor(arr)\n",
    "\n",
    "\n",
    "class CustomDataSet:\n",
    "    def __init__(self, data, targets, transform = None):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        target = conv(self.targets[idx])\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, target\n",
    "    \n",
    "customData = CustomDataSet(data=train_data.data, targets=train_data.targets, transform=fix_input)\n",
    "train_loader = DataLoader(dataset=customData, batch_size=10, shuffle=True, num_workers=1)\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, lr):\n",
    "        # torch.manual_seed(1)\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(1, 10, 3)\n",
    "        self.m1 = nn.MaxPool2d(2)\n",
    "        self.c2 = nn.Conv2d(10, 20, 3)\n",
    "        self.m2 = nn.MaxPool2d(2)\n",
    "        self.f1 = nn.Linear(20 * 5 * 5, 50)  # Adjusted based on convolution and pooling operations\n",
    "        self.f2 = nn.Linear(50, 10)\n",
    "\n",
    "        self.weights = [self.c1.weight, self.f1.weight, self.f2.weight]\n",
    "        self.biases = [self.c1.bias, self.f1.bias, self.f2.bias]\n",
    "\n",
    "        self.lr = lr\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.SGD(self.weights + self.biases, lr = self.lr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.c1(x))\n",
    "        x = self.m1(x)\n",
    "        x = torch.relu(self.c2(x))\n",
    "        x = self.m2(x)\n",
    "        x = x.view(-1, 20 * 5 * 5)  # Flatten the tensor for fully connected layers\n",
    "        x = torch.relu(self.f1(x))\n",
    "        x = self.f2(x)\n",
    "        return x\n",
    "\n",
    "    def conv(self, y):\n",
    "        arr = [0]*10\n",
    "        arr[int(y.item())] = 1.0\n",
    "        return torch.tensor([arr], device=device)\n",
    "\n",
    "    def predict(self, y):\n",
    "        m = 0\n",
    "        I = 0\n",
    "        for i in range(10):\n",
    "            if y[0][i] > m:\n",
    "                I = i\n",
    "                m = y[0][i]\n",
    "        return I\n",
    "\n",
    "    def train(self, training_loader, testing_data):\n",
    "        testing_data.data, testing_data.targets = testing_data.data.to(device), testing_data.targets.to(device)\n",
    "        for epoch in range(20):\n",
    "            for idx, (data, targets) in enumerate(training_loader):\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "                targets = targets.type(torch.float32)\n",
    "                y_pred = self(data.view([10, 1, 28, 28]))\n",
    "                y = targets\n",
    "                l = self.loss(y_pred, y)\n",
    "                l.backward()\n",
    "                self.optimizer.step()\n",
    "            correct = 0\n",
    "            for i in range(len(testing_data.data)):\n",
    "                y = self.forward(fix_input(testing_data.data[i]).view(1, 28, 28))\n",
    "                z = self.predict(y)\n",
    "                if z == testing_data.targets[i]:\n",
    "                    correct += 1\n",
    "            \n",
    "            print(f\"epoch {epoch}: {correct}/{len(testing_data.data)}\")\n",
    "        \n",
    "\n",
    "n = NeuralNet(lr=0.01)\n",
    "n.to(device)\n",
    "n.train(train_loader, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
